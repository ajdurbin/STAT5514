---
title: "Project 1"
subtitle: "Regression Analysis"
author: "Alexander Durbin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
options(stringsAsFactors = FALSE)
library(minpack.lm)
library(nls2)
library(mgcv)
library(robustbase)
```

For each of the following datasets we use the bootstrap to derive confidence intervals. To combat possible singularity errors, we include `try` statements when fitting the models and increase our bootstrap replications. 

# Herbicide
## First Observation

```{r}

# load data
raw <- read.csv("Herbicide.csv")
colnames(raw) <- NULL
raw <- raw[2:nrow(raw), ]
raw <- raw[, 2:ncol(raw)]

# choose obs
obs <- raw[, 1:2]
x <- as.numeric(obs[, 1])
y <- as.numeric(obs[, 2])

# storage
b_coef <- matrix(data = NA, ncol = 3, nrow = 2000)
ss_res <- rep(0, 2000)

# call
for(i in 1:2000){
  
  boot <- sample(1:7, 7, replace = TRUE)
  x_star <- x[boot]
  y_star <- y[boot]
  
  try({
    
    nlfit <- nls2(y_star ~ (p1 * p2 * x_star^p3) / (1 + p2 * x_star^p3), 
                start = c(p1 = 100, p2 = 1, p3 = -1),
                control = nls.control(maxiter = 1e3,
                                     minFactor = .Machine$double.eps,
                                     tol = 1e-5),
                algorithm = "default")
  }, silent = TRUE)
  
  b_coef[i, ] <- coefficients(nlfit)
  ss_res[i] <- sum(residuals(nlfit)^2)

}

# grab unique
b_coef <- unique(b_coef)
ss_res <- unique(ss_res)

summary(ss_res)

# compare best estimate from all 7 data points to mean of bootstrapped sample
best <- nls2(y ~ (p1 * p2 * x^p3) / (1 + p2 * x^p3), 
              start = c(p1 = 100, p2 = 1, p3 = -1),
              control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5),
              algorithm = "default")

coefficients(best)
c(mean(b_coef[, 1]), mean(b_coef[, 2]), mean(b_coef[, 3]))

# plot
plot(x, y)
pts <- seq(min(x), max(x), by = 0.01)
preds <- predict(best, pts)
lines(x, preds, lty = 1, col = "red", lwd = 3)


# ci
quantile(b_coef[, 1], probs = c(0.025, 0.975))
quantile(b_coef[, 2], probs = c(0.025, 0.975))
quantile(b_coef[, 3], probs = c(0.025, 0.975))

```

None of our confidence intervals contain 0, so we can claim that they are significantly different from 0. 

## Second Observation

```{r}

# load data
obs <- raw[, 3:4]
x <- as.numeric(obs[, 1])
y <- as.numeric(obs[, 2])

# storage
b_coef <- matrix(data = NA, ncol = 3, nrow = 2000)
ss_res <- rep(0, 2000)

# call
for(i in 1:2000){
  
  boot <- sample(1:7, 7, replace = TRUE)
  x_star <- x[boot]
  y_star <- y[boot]
  
  try({
    
    nlfit <- nls2(y_star ~ (p1 * p2 * x_star^p3) / (1 + p2 * x_star^p3), 
                start = c(p1 = 100, p2 = 1, p3 = -1),
                control = nls.control(maxiter = 1e3,
                                     minFactor = .Machine$double.eps,
                                     tol = 1e-5),
                algorithm = "default")
  }, silent = TRUE)
  
  b_coef[i, ] <- coefficients(nlfit)
  ss_res[i] <- sum(residuals(nlfit)^2)

}

# grab unique
b_coef <- unique(b_coef)
ss_res <- unique(ss_res)

summary(ss_res)

# compare best estimate from all 7 data points to mean of bootstrapped sample
best <- nls2(y ~ (p1 * p2 * x^p3) / (1 + p2 * x^p3), 
              start = c(p1 = 100, p2 = 1, p3 = -1),
              control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5),
              algorithm = "default")

coefficients(best)
c(mean(b_coef[, 1]), mean(b_coef[, 2]), mean(b_coef[, 3]))

# plot
plot(x, y)
pts <- seq(min(x), max(x), by = 0.01)
preds <- predict(best, pts)
lines(x, preds, lty = 1, col = "red", lwd = 3)


# ci
quantile(b_coef[, 1], probs = c(0.025, 0.975))
quantile(b_coef[, 2], probs = c(0.025, 0.975))
quantile(b_coef[, 3], probs = c(0.025, 0.975))

```

Similar to above, none of our confidence intervals contain 0, so we can claim that each of the coefficients is significantly different from 0.

# Efficiency

```{r, warning=FALSE}
 
# load data
raw <- read.csv("EffRange.csv")
raw <- raw[, 2:ncol(raw)]
obs <- raw[, 1:2]
colnames(obs) <- c('y', 'x')

# storage
b_coef <- matrix(data = NA, ncol = 3, nrow = 2000)
ss_res <- rep(0, 2000)

# bootstrap
for(i in 1:2000){

  boot <- sample(1:7, 7, replace = TRUE)
  boot_sample <- obs[boot, ]

  try({

    nlfit <- nlrob(formula = y ~ a / (1 + b * exp(-k * x)),
                  start = list(a = 40, b = 400, k = 0.1),
                  data = boot_sample,
                  control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5))
  }, silent = TRUE)

  b_coef[i, ] <- coefficients(nlfit)
  ss_res[i] <- sum(residuals(nlfit)^2)

}

# grab unique
b_coef <- unique(b_coef)
ss_res <- unique(ss_res)

summary(ss_res)

# compare best estimate from all 7 data points to mean of bootstrapped sample
best <- nlrob(formula = y ~ a / (1 + b * exp(-k * x)),
             start = list(a = 40, b = 40, k = 0.1),
             data = obs,
             control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5))

coefficients(best)
c(mean(b_coef[, 1]), mean(b_coef[, 2]), mean(b_coef[, 3]))

# plots
plot(obs$x, obs$y)
pts <- seq(min(obs$x), max(obs$x), by = 0.01)
preds <- predict(best, pts)
lines(obs$x, preds, lty = 1, col = "red", lwd = 3)

# ci
quantile(b_coef[, 1], probs = c(0.025, 0.975))
quantile(b_coef[, 2], probs = c(0.025, 0.975))
quantile(b_coef[, 3], probs = c(0.025, 0.975))

```
