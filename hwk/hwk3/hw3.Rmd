---
title: "Homework 3"
subtitle: 'STAT5514: Regression Analysis'
author: "Alexander Durbin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Summary

This paper is concerned with the bias that results from transforming non-linear data. The author considers cases where $X, Y$, or both are transformed such that residual assumptions are satisfied for linear regression. The author notes that after fitting a linear model, we can apply the inverse transformation to get confidence intervals and predicition intervals. However, if we are concerned with the mean response of $Y$ given $X$, data transformation can result in large bias of models. This paper suggests solutions for bias induced from common data transformations. The author considers four cases of transformation. Each case includes a bias-adjustment factor that eliminates a large portion of bias for each model. Furthermoer, the resulting bias-adjusted estimates are still slightly biased because the data transformations consist of non-linear functions of parameters. The paper concludes with a short discussion on more advanced techniques for reducing bias and notes that these techniques may not be very useful in practice.

# Impressions

Overall, I thought this paper discussed a very relevant problem in my statistical education thus far. While theoretically we can focus on estiamtes that are BLUE or UMVUE, in practice data is not that well-behaved. Instead, the author focuses on common transformations and how to reduce their bias. Though discussing very applicable results, I think including a simulation study beyond the logarithm section would be useful. I found this paper accessible, though a little too concise mathematically.

# Criticisms

- Typos in derivations. When discussing transformations using positive fractional powers, Equation 4.9 should be $E(Y) = (\beta_0 + \beta_1 X)^2 + \sigma^2$, not $E(Y) = (\beta_0 + \beta_1 X) + \sigma^2$.

- While the author provided excellent motivation for the topic and mentions that the more advanced techniques are not useful practically, it would have been beneficial to see a simulation study to analytically illustrate this.

- The paragraph following Equation 4.12 should derive the geometric progression and truncation and not just describe it. Furthermore, how this results in $\sigma^2$ in the numerator of Equation 4.13. 

- In logarithm and positive fractional power transformations, the bias-adjustment factor is simply the variance estimate, $\hat{\sigma}^2$. But in inverse transformations, the bracketed term in Equation 4.13 is the bias-adjustment factor, it is not clear whether this is simply because this term contains $\sigma^2$ or not.

- Similar to above, the author does not state what the bias-adjustment factor is in Equation 4.14. Both terms contain $\sigma^2$ here. Again, if the bias-adjustment factor is simply $\sigma^2$, this point is moot.

- The author does not discuss or mention how these results affect multiple regression.

# Bias Results