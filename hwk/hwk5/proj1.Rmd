---
title: "Project 1"
subtitle: "Regression Analysis"
author: "Alexander Durbin"
date: "`r Sys.Date()`"
output: html_document
abstract: "This paper concerns itself with nonlinear regression. We look at two different datasets where either the true underlying model is known or unknown. We compare multiple models with the deviance measure, AIC, and BIC. We then make inference with boostrap confidence intervals. On this basis we choose a best fitting model."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
options(stringsAsFactors = FALSE)
library(minpack.lm)
library(nls2)
library(mgcv)
library(robustbase)
library(faraway)
library(lawstat)
library(lmtest)
```

# Problem 1

## Introduction

Our data concists of the efficiency for krigging of different soil attributes as a function of the spatial correlation range. Specific soil attributes are 1:1 soil water mixture, extractable soil phosphorus, calcium extractable, cation exchange capacity, and lime and P fertilizer recommendations. We begin with a scatter plot and simple regression diagnostics.

```{r}

raw <- read.csv("EffRange.csv")
raw <- raw[, 2:ncol(raw)]
obs <- raw[, 1:2]
colnames(obs) <- c('y', 'x')

# simple linear regression fit
lmfit <- lm(y ~ x, data = obs)
cook <- cooks.distance(lmfit)

```

```{r, fig.cap="Scatter plot of Range versus Efficiency. There is clearly a nonlinear relationship between the two variables."}

plot(obs$x, obs$y, xlab = "Range", ylab = "Efficiency", main = "Scatter plot of Range Versus Efficiency")

```

```{r, fig.cap="Histogram of residuals from linear fit. The residuals do not appear normally distributed."}

hist(residuals(lmfit), main = "Residuals From Linear Fit", xlab = "Residuals")

```

```{r}

runs.test(residuals(lmfit))

```

Result of Runs Test. We fail to reject the null, so the residuals are iid.

```{r}

shapiro.test(residuals(lmfit))

```

Result of Shapiro-Wilk test for normality. Surprisingly, the residuals are normally distributed.

```{r}

bptest(lmfit)

```

Additionally, the data satisfy constant variance.

```{r, fig.cap="Various Linear Model Diagnostic Plots."}

par(mfrow=c(2,2))
halfnorm(cook, 3, ylab = "Cooks Distance", main = "Residual Cooks Distance")
plot(fitted(lmfit), residuals(lmfit), xlab = "Fitted", ylab = "Residuals", main = "Residuals Versus Fitted")
abline(h=0)
plot(fitted(lmfit), abs(residuals(lmfit)), xlab = "Fitted", ylab = "|Residuals|", main = "|Residuals| Versus Fitted")
abline(h=0)
qqnorm(residuals(lmfit))
qqline(residuals(lmfit))

```

In the simple linear regression setting, it appears that we do havee a single outlier. Furthermore, all of our simple linear regression diagnostics hold. So how well does a simple linear regression line fit? 

```{r, fig.cap="Fitted regression line predicting Efficiency from Range. We see that the regression line does not follow the curvature."}

summary(lmfit)
paste0("Deviance: ", deviance(lmfit))
paste0("AIC: ", AIC(lmfit))
paste0("BIC: ", BIC(lmfit))
plot(obs$x, obs$y, xlab = "Range", ylab = "Efficiency", main = "Scatter plot of Range Versus Efficiency")
abline(lmfit)

```

From the linear model summary output, we see that neither coefficients are significant, the F-statistic is not significant, and the Adjusted R-squared is very poor. We also get a deviance measure of the model fit with the AIC and BIC criterion. 

The above results show that a linear model is not an appropriate choice for this data.

### Model 1

\[
y = \frac{\beta_0}{1 + exp(\beta_1 + \beta_2x)} + \epsilon
\]

The first model we consider is an exponential growth model. It has several nice properties that suggest it is an appropriate choice and is similar to a logistic model. Here, $\beta_0$ is the horizontal asymptote, $\beta_1$ is the y-intercept, and $\beta_2$ is the growth rate. We make visual guesses of these three parameters before fitting the nonlinear regression based on this model. We give three measures of model fit and confidence intervals for the coefficients. 

```{r, fig.cap="Nonlinear regression model fit for the population growth model."}

# storage
b_coef <- matrix(data = NA, ncol = 3, nrow = 2000)
ss_res <- rep(0, 2000)

for(i in 1:2000){

  boot <- sample(1:7, 7, replace = TRUE)
  boot_sample <- obs[boot, ]

  try({

    # logistic growth model
    nlfit <- nls2(formula = y ~ a / (1 + exp(b + k * x)),
                  start = list(a = 100, b = 2.5, k = -0.1),
                  data = boot_sample,
                  control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5),
                  algorithm = "default")
    
    b_coef[i, ] <- coefficients(nlfit)
    ss_res[i] <- sum(residuals(nlfit)^2)
    
  }, silent = TRUE)

}

b_coef <- unique(na.omit(b_coef))
ss_res <- unique(na.omit(ss_res))

best <- nls2(formula = y ~ a / (1 + exp(b + k * x)),
             start = list(a = 100, b = 2.5, k = -0.1),
             data = obs,
             control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5),
             algorithm = "default")

# function for predictions
my_func1 <- function(boot_co, dat){
  
  a <- mean(boot_co[, 1])
  b <- mean(boot_co[, 2])
  c <- mean(boot_co[, 3])
  pckg <- a / (1 + exp(b + c*dat))
  return(pckg)
  
}

# plots
pts <- seq(min(obs$x), max(obs$x), by = 0.01)
preds <- my_func1(boot_co = b_coef, dat = pts)
plot(obs$x, obs$y, xlab = "Range", ylab = "Efficiency", main = "Population Growth Model Fit")
lines(pts, preds, lty = 1, col = "red", lwd = 3)

```

```{r}

summary(best)
paste0("Bootstrapped Mean Coefficient, beta_0: ", mean(b_coef[, 1]))
paste0("Bootstrapped Mean Coefficient, beta_1: ", mean(b_coef[, 2]))
paste0("Bootstrapped Mean Coefficient, beta_2: ", mean(b_coef[, 3]))

paste0("beta_0 bootstrap ci: ", quantile(b_coef[, 1], probs = c(0.025, 0.975)))
paste0("beta_1 bootstrap ci: ", quantile(b_coef[, 2], probs = c(0.025, 0.975)))
paste0("beta_2 bootstrap ci: ", quantile(b_coef[, 3], probs = c(0.025, 0.975)))

paste0("Deviance: ", deviance(best))
paste0("AIC: ", AIC(best))
paste0("BIC: ", BIC(best))

```

### Model 2

\[
y = \frac{\beta_0(x^2+x\beta_1)}{x^2+x\beta_2+\beta_3} + \epsilon
\]

```{r, fig.cap="Nonlinear regression model fit for the population growth model."}

# storage
b_coef <- matrix(data = NA, ncol = 4, nrow = 2000)
ss_res <- rep(0, 2000)

for(i in 1:2000){

  boot <- sample(1:7, 7, replace = TRUE)
  boot_sample <- obs[boot, ]

  try({

    # logistic growth model
    nlfit <- nls2(formula = y ~ a*(x^2+b*x)/(x^2+x*d+e),
             start = list(a = 32.6, b = -40, d = -63, e = 1650),
             data = boot_sample,
             control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5),
             algorithm = "default")
    
    b_coef[i, ] <- coefficients(nlfit)
    ss_res[i] <- sum(residuals(nlfit)^2)
    
  }, silent = TRUE)

}

b_coef <- unique(na.omit(b_coef))
ss_res <- unique(na.omit(ss_res))

best <- nls2(formula = y ~ a*(x^2+b*x)/(x^2+x*d+e),
             start = list(a = 32.6, b = -40, d = -63, e = 1650),
             data = obs,
             control = nls.control(maxiter = 1e3,
                                    minFactor = .Machine$double.eps,
                                    tol = 1e-5),
             algorithm = "default")

# function for predictions
# my_func1 <- function(boot_co, dat){
#   
#   a <- mean(boot_co[, 1])
#   b <- mean(boot_co[, 2])
#   d <- mean(boot_co[, 3])
#   e <- mean(boot_co[, 4])
#   pckg <- a*(dat^2 + dat*b) / (dat^2 + dat*d+e)
#   return(pckg)
#   
# }

# plots
# pts <- seq(min(obs$x), max(obs$x), by = 0.01)
# preds <- my_func1(boot_co = b_coef, dat = pts)
plot(obs$x, obs$y, xlab = "Range", ylab = "Efficiency", main = "Population Growth Model Fit")
abline(best)
# lines(pts, preds, lty = 1, col = "red", lwd = 3)

```

```{r}

summary(best)
paste0("Bootstrapped Mean Coefficient, beta_0: ", mean(b_coef[, 1]))
paste0("Bootstrapped Mean Coefficient, beta_1: ", mean(b_coef[, 2]))
paste0("Bootstrapped Mean Coefficient, beta_2: ", mean(b_coef[, 3]))
paste0("Bootstrapped Mean Coefficient, beta_3: ", mean(b_coef[, 4]))

paste0("beta_0 bootstrap ci: ", quantile(b_coef[, 1], probs = c(0.025, 0.975)))
paste0("beta_1 bootstrap ci: ", quantile(b_coef[, 2], probs = c(0.025, 0.975)))
paste0("beta_2 bootstrap ci: ", quantile(b_coef[, 3], probs = c(0.025, 0.975)))
paste0("beta_3 bootstrap ci: ", quantile(b_coef[, 4], probs = c(0.025, 0.975)))

paste0("Deviance: ", deviance(best))
paste0("AIC: ", AIC(best))
paste0("BIC: ", BIC(best))

```
